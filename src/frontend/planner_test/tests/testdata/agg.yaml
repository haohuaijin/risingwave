# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- sql: |
    values(sum(1));
  binder_error: 'Invalid input syntax: aggregate functions are not allowed in VALUES'
- sql: |
    values(count(1));
  binder_error: 'Invalid input syntax: aggregate functions are not allowed in VALUES'
- sql: |
    values(min(1));
  binder_error: 'Invalid input syntax: aggregate functions are not allowed in VALUES'
- sql: |
    values(1 + max(1));
  binder_error: 'Invalid input syntax: aggregate functions are not allowed in VALUES'
- sql: |
    create table t (v1 int);
    select v1 from t where min(v1);
  binder_error: 'Invalid input syntax: aggregate functions are not allowed in WHERE'
- sql: |
    create table t(v1 int, v2 int, v3 int);
    select v1, min(v2) + max(v3) * count(v1) as agg from t group by v1;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t.v1, (min(t.v2) + (max(t.v3) * count(t.v1))) as $expr1] }
      └─BatchHashAgg { group_key: [t.v1], aggs: [min(t.v2), max(t.v3), count(t.v1)] }
        └─BatchExchange { order: [], dist: HashShard(t.v1) }
          └─BatchScan { table: t, columns: [t.v1, t.v2, t.v3], distribution: SomeShard }
  batch_local_plan: |
    BatchProject { exprs: [t.v1, (min(t.v2) + (max(t.v3) * count(t.v1))) as $expr1] }
    └─BatchHashAgg { group_key: [t.v1], aggs: [min(t.v2), max(t.v3), count(t.v1)] }
      └─BatchExchange { order: [], dist: Single }
        └─BatchScan { table: t, columns: [t.v1, t.v2, t.v3], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [v1, agg], pk_columns: [v1], pk_conflict: "no check" }
    └─StreamProject { exprs: [t.v1, (min(t.v2) + (max(t.v3) * count(t.v1))) as $expr1] }
      └─StreamHashAgg { group_key: [t.v1], aggs: [min(t.v2), max(t.v3), count(t.v1), count] }
        └─StreamExchange { dist: HashShard(t.v1) }
          └─StreamTableScan { table: t, columns: [t.v1, t.v2, t.v3, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    create table t(v1 int, v2 int, v3 int);
    select min(v1) + max(v2) * count(v3) as agg from t;
  batch_plan: |
    BatchProject { exprs: [(min(min(t.v1)) + (max(max(t.v2)) * sum0(count(t.v3)))) as $expr1] }
    └─BatchSimpleAgg { aggs: [min(min(t.v1)), max(max(t.v2)), sum0(count(t.v3))] }
      └─BatchExchange { order: [], dist: Single }
        └─BatchSimpleAgg { aggs: [min(t.v1), max(t.v2), count(t.v3)] }
          └─BatchScan { table: t, columns: [t.v1, t.v2, t.v3], distribution: SomeShard }
  batch_local_plan: |
    BatchProject { exprs: [(min(t.v1) + (max(t.v2) * count(t.v3))) as $expr1] }
    └─BatchSimpleAgg { aggs: [min(t.v1), max(t.v2), count(t.v3)] }
      └─BatchExchange { order: [], dist: Single }
        └─BatchScan { table: t, columns: [t.v1, t.v2, t.v3], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [agg], pk_columns: [], pk_conflict: "no check" }
    └─StreamProject { exprs: [(min(min(t.v1)) + (max(max(t.v2)) * sum0(count(t.v3)))) as $expr2] }
      └─StreamGlobalSimpleAgg { aggs: [min(min(t.v1)), max(max(t.v2)), sum0(count(t.v3)), count] }
        └─StreamExchange { dist: Single }
          └─StreamHashAgg { group_key: [$expr1], aggs: [min(t.v1), max(t.v2), count(t.v3), count] }
            └─StreamProject { exprs: [t.v1, t.v2, t.v3, t._row_id, Vnode(t._row_id) as $expr1] }
              └─StreamTableScan { table: t, columns: [t.v1, t.v2, t.v3, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    create table t(v1 int, v2 int);
    select v1 from t group by v2;
  planner_error: 'Invalid input syntax: column must appear in the GROUP BY clause or be used in an aggregate function'
- sql: |
    create table t(v1 int, v2 int);
    select sum(v1), v1 from t group by v2, v2;
  planner_error: 'Invalid input syntax: column must appear in the GROUP BY clause or be used in an aggregate function'
- sql: |
    create table t(v1 int, v2 int, v3 int);
    select v3, min(v1) * avg(v1+v2) as agg from t group by v3;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t.v3, (min(t.v1) * (sum($expr1)::Decimal / count($expr1))) as $expr2] }
      └─BatchHashAgg { group_key: [t.v3], aggs: [min(t.v1), sum($expr1), count($expr1)] }
        └─BatchExchange { order: [], dist: HashShard(t.v3) }
          └─BatchProject { exprs: [t.v3, t.v1, (t.v1 + t.v2) as $expr1] }
            └─BatchScan { table: t, columns: [t.v1, t.v2, t.v3], distribution: SomeShard }
  batch_local_plan: |
    BatchProject { exprs: [t.v3, (min(t.v1) * (sum($expr1)::Decimal / count($expr1))) as $expr2] }
    └─BatchHashAgg { group_key: [t.v3], aggs: [min(t.v1), sum($expr1), count($expr1)] }
      └─BatchExchange { order: [], dist: Single }
        └─BatchProject { exprs: [t.v3, t.v1, (t.v1 + t.v2) as $expr1] }
          └─BatchScan { table: t, columns: [t.v1, t.v2, t.v3], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [v3, agg], pk_columns: [v3], pk_conflict: "no check" }
    └─StreamProject { exprs: [t.v3, (min(t.v1) * (sum($expr1)::Decimal / count($expr1))) as $expr2] }
      └─StreamHashAgg { group_key: [t.v3], aggs: [min(t.v1), sum($expr1), count($expr1), count] }
        └─StreamExchange { dist: HashShard(t.v3) }
          └─StreamProject { exprs: [t.v3, t.v1, (t.v1 + t.v2) as $expr1, t._row_id] }
            └─StreamTableScan { table: t, columns: [t.v1, t.v2, t.v3, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: test logical_agg with complex group expression
  sql: |
    create table t(v1 int, v2 int);
    select min(v1), sum(v1 + v2) from t group by v1 + v2;
  logical_plan: |
    LogicalProject { exprs: [min(t.v1), sum($expr1)] }
    └─LogicalAgg { group_key: [$expr1], aggs: [min(t.v1), sum($expr1)] }
      └─LogicalProject { exprs: [(t.v1 + t.v2) as $expr1, t.v1] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id] }
- name: test logical_agg with complex group expression
  sql: |
    create table t(v1 int, v2 int, v3 int);
    select v1, sum(v1 * v2) as sum from t group by (v1 + v2) / v3, v1;
  logical_plan: |
    LogicalProject { exprs: [t.v1, sum($expr2)] }
    └─LogicalAgg { group_key: [$expr1, t.v1], aggs: [sum($expr2)] }
      └─LogicalProject { exprs: [((t.v1 + t.v2) / t.v3) as $expr1, t.v1, (t.v1 * t.v2) as $expr2] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t.v3, t._row_id] }
- name: test logical_agg with complex group expression
  sql: |
    create table t(v1 int, v2 int);
    select v1 + v2 from t group by v1 + v2;
  logical_plan: |
    LogicalProject { exprs: [$expr1] }
    └─LogicalAgg { group_key: [$expr1], aggs: [] }
      └─LogicalProject { exprs: [(t.v1 + t.v2) as $expr1] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id] }
- name: "test logical_agg with complex group expression \nshould complain about nested agg call \n"
  sql: |
    create table t(v1 int, v2 int);
    select avg(sum(v1 + v2)) from t group by v1 + v2;
  planner_error: |-
    Feature is not yet implemented: aggregate function inside aggregation calls
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- name: test logical_agg with complex select expression
  sql: |
    create table t(v1 int, v2 int);
    select v1 + v2 from t group by v1, v2;
  logical_plan: |
    LogicalProject { exprs: [(t.v1 + t.v2) as $expr1] }
    └─LogicalAgg { group_key: [t.v1, t.v2], aggs: [] }
      └─LogicalProject { exprs: [t.v1, t.v2] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id] }
- sql: |
    create table t(v1 int, v2 int);
    select v1 from t group by v1 + v2;
  planner_error: 'Invalid input syntax: column must appear in the GROUP BY clause or be used in an aggregate function'
- sql: |
    create table t(v1 int, v2 int);
    select count(v1 + v2) as cnt, sum(v1 + v2) as sum from t;
  batch_plan: |
    BatchSimpleAgg { aggs: [sum0(count($expr1)), sum(sum($expr1))] }
    └─BatchExchange { order: [], dist: Single }
      └─BatchSimpleAgg { aggs: [count($expr1), sum($expr1)] }
        └─BatchProject { exprs: [(t.v1 + t.v2) as $expr1] }
          └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
  batch_local_plan: |
    BatchSimpleAgg { aggs: [count($expr1), sum($expr1)] }
    └─BatchExchange { order: [], dist: Single }
      └─BatchProject { exprs: [(t.v1 + t.v2) as $expr1] }
        └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [cnt, sum], pk_columns: [], pk_conflict: "no check" }
    └─StreamProject { exprs: [sum0(count($expr1)), sum(sum($expr1))] }
      └─StreamGlobalSimpleAgg { aggs: [sum0(count($expr1)), sum(sum($expr1)), count] }
        └─StreamExchange { dist: Single }
          └─StreamStatelessLocalSimpleAgg { aggs: [count($expr1), sum($expr1)] }
            └─StreamProject { exprs: [(t.v1 + t.v2) as $expr1, t._row_id] }
              └─StreamTableScan { table: t, columns: [t.v1, t.v2, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    create table t(v1 int, v2 int, v3 int);
    select v1, sum(v2 + v3) / count(v2 + v3) + max(v1) as agg from t group by v1;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t.v1, ((sum($expr1) / count($expr1)) + max(t.v1)) as $expr2] }
      └─BatchHashAgg { group_key: [t.v1], aggs: [sum($expr1), count($expr1), max(t.v1)] }
        └─BatchExchange { order: [], dist: HashShard(t.v1) }
          └─BatchProject { exprs: [t.v1, (t.v2 + t.v3) as $expr1] }
            └─BatchScan { table: t, columns: [t.v1, t.v2, t.v3], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [v1, agg], pk_columns: [v1], pk_conflict: "no check" }
    └─StreamProject { exprs: [t.v1, ((sum($expr1) / count($expr1)) + max(t.v1)) as $expr2] }
      └─StreamHashAgg { group_key: [t.v1], aggs: [sum($expr1), count($expr1), max(t.v1), count] }
        └─StreamExchange { dist: HashShard(t.v1) }
          └─StreamProject { exprs: [t.v1, (t.v2 + t.v3) as $expr1, t._row_id] }
            └─StreamTableScan { table: t, columns: [t.v1, t.v2, t.v3, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    create table t (v1 real);
    select v1, count(*) from t group by v1;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchHashAgg { group_key: [t.v1], aggs: [count] }
      └─BatchExchange { order: [], dist: HashShard(t.v1) }
        └─BatchScan { table: t, columns: [t.v1], distribution: SomeShard }
- name: Use BatchSortAgg, when input provides order
  sql: |
    create table t(v1 int, v2 int);
    create materialized view mv as select * from t order by v1 desc;
    select v1, max(v2) from mv group by v1;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchSortAgg { group_key: [mv.v1], aggs: [max(mv.v2)] }
      └─BatchExchange { order: [mv.v1 DESC], dist: HashShard(mv.v1) }
        └─BatchScan { table: mv, columns: [mv.v1, mv.v2], distribution: SomeShard }
- name: Use BatchSortAgg, when output requires order
  sql: |
    create table t(v1 int, v2 int);
    select v1, max(v2) from t group by v1 order by v1 desc;
  batch_plan: |
    BatchExchange { order: [t.v1 DESC], dist: Single }
    └─BatchSortAgg { group_key: [t.v1], aggs: [max(t.v2)] }
      └─BatchExchange { order: [t.v1 DESC], dist: HashShard(t.v1) }
        └─BatchSort { order: [t.v1 DESC] }
          └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
- name: Use BatchSortAgg, when required order satisfies input order
  sql: |
    create table t(k1 int, k2 int, v1 int);
    SELECT max(v1), k1, k2 from t group by k1, k2 order by k1;
  batch_plan: |
    BatchExchange { order: [t.k1 ASC], dist: Single }
    └─BatchProject { exprs: [max(t.v1), t.k1, t.k2] }
      └─BatchSortAgg { group_key: [t.k1, t.k2], aggs: [max(t.v1)] }
        └─BatchExchange { order: [t.k1 ASC, t.k2 ASC], dist: HashShard(t.k1, t.k2) }
          └─BatchSort { order: [t.k1 ASC, t.k2 ASC] }
            └─BatchScan { table: t, columns: [t.k1, t.k2, t.v1], distribution: SomeShard }
- name: Use BatchSortAgg, when output requires order with swapped output
  sql: |
    create table t(v1 int, v2 int);
    select max(v2), v1 from t group by v1 order by v1 desc;
  batch_plan: |
    BatchExchange { order: [t.v1 DESC], dist: Single }
    └─BatchProject { exprs: [max(t.v2), t.v1] }
      └─BatchSortAgg { group_key: [t.v1], aggs: [max(t.v2)] }
        └─BatchExchange { order: [t.v1 DESC], dist: HashShard(t.v1) }
          └─BatchSort { order: [t.v1 DESC] }
            └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
- name: Not use BatchSortAgg, when input provides order
  sql: |
    create table t(v1 int, v2 int);
    create materialized view mv as select * from t order by v1 desc;
    select v1, max(v2) from mv group by v1;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchHashAgg { group_key: [mv.v1], aggs: [max(mv.v2)] }
      └─BatchExchange { order: [], dist: HashShard(mv.v1) }
        └─BatchScan { table: mv, columns: [mv.v1, mv.v2], distribution: SomeShard }
  with_config_map:
    RW_BATCH_ENABLE_SORT_AGG: 'false'
- name: Not use BatchSortAgg, when output requires order
  sql: |
    create table t(v1 int, v2 int);
    select v1, max(v2) from t group by v1 order by v1 desc;
  batch_plan: |
    BatchExchange { order: [t.v1 DESC], dist: Single }
    └─BatchSort { order: [t.v1 DESC] }
      └─BatchHashAgg { group_key: [t.v1], aggs: [max(t.v2)] }
        └─BatchExchange { order: [], dist: HashShard(t.v1) }
          └─BatchSort { order: [t.v1 DESC] }
            └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
  with_config_map:
    RW_BATCH_ENABLE_SORT_AGG: 'false'
- name: Not use BatchSortAgg, when required order satisfies input order
  sql: |
    create table t(k1 int, k2 int, v1 int);
    SELECT max(v1), k1, k2 from t group by k1, k2 order by k1;
  batch_plan: |
    BatchExchange { order: [t.k1 ASC], dist: Single }
    └─BatchProject { exprs: [max(t.v1), t.k1, t.k2] }
      └─BatchSort { order: [t.k1 ASC] }
        └─BatchHashAgg { group_key: [t.k1, t.k2], aggs: [max(t.v1)] }
          └─BatchExchange { order: [], dist: HashShard(t.k1, t.k2) }
            └─BatchSort { order: [t.k1 ASC, t.k2 ASC] }
              └─BatchScan { table: t, columns: [t.k1, t.k2, t.v1], distribution: SomeShard }
  with_config_map:
    RW_BATCH_ENABLE_SORT_AGG: 'false'
- name: Not use BatchSortAgg, when output requires order with swapped output
  sql: |
    create table t(v1 int, v2 int);
    select max(v2), v1 from t group by v1 order by v1 desc;
  batch_plan: |
    BatchExchange { order: [t.v1 DESC], dist: Single }
    └─BatchProject { exprs: [max(t.v2), t.v1] }
      └─BatchSort { order: [t.v1 DESC] }
        └─BatchHashAgg { group_key: [t.v1], aggs: [max(t.v2)] }
          └─BatchExchange { order: [], dist: HashShard(t.v1) }
            └─BatchSort { order: [t.v1 DESC] }
              └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
  with_config_map:
    RW_BATCH_ENABLE_SORT_AGG: 'false'
- sql: |
    create table t (v1 real);
    select count(*) from t;
  batch_plan: |
    BatchSimpleAgg { aggs: [sum0(count)] }
    └─BatchExchange { order: [], dist: Single }
      └─BatchSimpleAgg { aggs: [count] }
        └─BatchScan { table: t, columns: [], distribution: SomeShard }
- name: having with agg call
  sql: |
    create table t (v1 real);
    select 1 from t having sum(v1) > 5;
  batch_plan: |
    BatchProject { exprs: [1:Int32] }
    └─BatchFilter { predicate: (sum(sum(t.v1)) > 5:Int32) }
      └─BatchSimpleAgg { aggs: [sum(sum(t.v1))] }
        └─BatchExchange { order: [], dist: Single }
          └─BatchSimpleAgg { aggs: [sum(t.v1)] }
            └─BatchScan { table: t, columns: [t.v1], distribution: SomeShard }
- name: having with group column
  sql: |
    create table t (v1 real);
    select 1 from t group by v1 having v1 > 5;
  logical_plan: |
    LogicalProject { exprs: [1:Int32] }
    └─LogicalFilter { predicate: (t.v1 > 5:Int32) }
      └─LogicalAgg { group_key: [t.v1], aggs: [] }
        └─LogicalProject { exprs: [t.v1] }
          └─LogicalScan { table: t, columns: [t.v1, t._row_id] }
- name: having with non-group column
  sql: |
    create table t (v1 real, v2 int);
    select 1 from t group by v1 having v2 > 5;
  planner_error: 'Invalid input syntax: column must appear in the GROUP BY clause or be used in an aggregate function'
- name: distinct without agg
  sql: |
    create table t (v1 int, v2 int);
    select distinct v1 from t;
  logical_plan: |
    LogicalAgg { group_key: [t.v1], aggs: [] }
    └─LogicalProject { exprs: [t.v1] }
      └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id] }
- name: distinct with agg
  sql: |
    create table t (v1 int, v2 int);
    select distinct sum(v1) from t group by v2;
  logical_plan: |
    LogicalAgg { group_key: [sum(t.v1)], aggs: [] }
    └─LogicalProject { exprs: [sum(t.v1)] }
      └─LogicalAgg { group_key: [t.v2], aggs: [sum(t.v1)] }
        └─LogicalProject { exprs: [t.v2, t.v1] }
          └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id] }
- name: distinct on
  sql: |
    create table t (v1 int, v2 int, v3 int);
    select distinct on (v1, v3) v1, v2 from t order by v3, v1;
  logical_plan: |
    LogicalProject { exprs: [t.v1, t.v2] }
    └─LogicalTopN { order: "[t.v3 ASC, t.v1 ASC]", limit: 1, offset: 0, group_key: [0, 2] }
      └─LogicalProject { exprs: [t.v1, t.v2, t.v3] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t.v3, t._row_id] }
  batch_plan: |
    BatchProject { exprs: [t.v1, t.v2] }
    └─BatchExchange { order: [t.v3 ASC, t.v1 ASC], dist: Single }
      └─BatchGroupTopN { order: "[t.v3 ASC, t.v1 ASC]", limit: 1, offset: 0, group_key: [0, 2] }
        └─BatchExchange { order: [], dist: HashShard(t.v1, t.v3) }
          └─BatchScan { table: t, columns: [t.v1, t.v2, t.v3], distribution: SomeShard }
- name: distinct on
  sql: |
    create table t (v1 int, v2 int, v3 int);
    select distinct on (v1, v3) v1, v2 from t order by v1, v3;
  logical_plan: |
    LogicalProject { exprs: [t.v1, t.v2] }
    └─LogicalTopN { order: "[t.v1 ASC, t.v3 ASC]", limit: 1, offset: 0, group_key: [0, 2] }
      └─LogicalProject { exprs: [t.v1, t.v2, t.v3] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t.v3, t._row_id] }
  batch_plan: |
    BatchProject { exprs: [t.v1, t.v2] }
    └─BatchExchange { order: [t.v1 ASC, t.v3 ASC], dist: Single }
      └─BatchGroupTopN { order: "[t.v1 ASC, t.v3 ASC]", limit: 1, offset: 0, group_key: [0, 2] }
        └─BatchExchange { order: [], dist: HashShard(t.v1, t.v3) }
          └─BatchScan { table: t, columns: [t.v1, t.v2, t.v3], distribution: SomeShard }
- name: distinct on
  sql: |
    create table t (v1 int, v2 int);
    select distinct on (v1) v1, v2 from t order by v1;
  logical_plan: |
    LogicalTopN { order: "[t.v1 ASC]", limit: 1, offset: 0, group_key: [0] }
    └─LogicalProject { exprs: [t.v1, t.v2] }
      └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id] }
- name: distinct on
  sql: |
    create table t (v1 int, v2 int, v3 int);
    select distinct on(v1) v2 + v3 from t order by v1;
  logical_plan: |
    LogicalProject { exprs: [$expr1] }
    └─LogicalTopN { order: "[t.v1 ASC]", limit: 1, offset: 0, group_key: [1] }
      └─LogicalProject { exprs: [(t.v2 + t.v3) as $expr1, t.v1] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t.v3, t._row_id] }
  batch_plan: |
    BatchProject { exprs: [$expr1] }
    └─BatchExchange { order: [t.v1 ASC], dist: Single }
      └─BatchGroupTopN { order: "[t.v1 ASC]", limit: 1, offset: 0, group_key: [1] }
        └─BatchExchange { order: [], dist: HashShard(t.v1) }
          └─BatchProject { exprs: [(t.v2 + t.v3) as $expr1, t.v1] }
            └─BatchScan { table: t, columns: [t.v1, t.v2, t.v3], distribution: SomeShard }
- name: arguments out-of-order
  sql: |
    create table t(v1 int, v2 int, v3 int);
    select count(v3), min(v2), max(v1) from t;
  logical_plan: |
    LogicalProject { exprs: [count(t.v3), min(t.v2), max(t.v1)] }
    └─LogicalAgg { aggs: [count(t.v3), min(t.v2), max(t.v1)] }
      └─LogicalProject { exprs: [t.v3, t.v2, t.v1] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t.v3, t._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalAgg { aggs: [count(t.v3), min(t.v2), max(t.v1)] }
    └─LogicalScan { table: t, columns: [t.v1, t.v2, t.v3] }
  batch_plan: |
    BatchSimpleAgg { aggs: [sum0(count(t.v3)), min(min(t.v2)), max(max(t.v1))] }
    └─BatchExchange { order: [], dist: Single }
      └─BatchSimpleAgg { aggs: [count(t.v3), min(t.v2), max(t.v1)] }
        └─BatchScan { table: t, columns: [t.v1, t.v2, t.v3], distribution: SomeShard }
- name: simple-agg arguments out-of-order
  sql: |
    create table t(v1 int, v2 int, v3 int);
    select min(v1) + max(v3) * count(v2) as agg from t;
  logical_plan: |
    LogicalProject { exprs: [(min(t.v1) + (max(t.v3) * count(t.v2))) as $expr1] }
    └─LogicalAgg { aggs: [min(t.v1), max(t.v3), count(t.v2)] }
      └─LogicalProject { exprs: [t.v1, t.v3, t.v2] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t.v3, t._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalProject { exprs: [(min(t.v1) + (max(t.v3) * count(t.v2))) as $expr1] }
    └─LogicalAgg { aggs: [min(t.v1), max(t.v3), count(t.v2)] }
      └─LogicalScan { table: t, columns: [t.v1, t.v2, t.v3] }
  batch_plan: |
    BatchProject { exprs: [(min(min(t.v1)) + (max(max(t.v3)) * sum0(count(t.v2)))) as $expr1] }
    └─BatchSimpleAgg { aggs: [min(min(t.v1)), max(max(t.v3)), sum0(count(t.v2))] }
      └─BatchExchange { order: [], dist: Single }
        └─BatchSimpleAgg { aggs: [min(t.v1), max(t.v3), count(t.v2)] }
          └─BatchScan { table: t, columns: [t.v1, t.v2, t.v3], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [agg], pk_columns: [], pk_conflict: "no check" }
    └─StreamProject { exprs: [(min(min(t.v1)) + (max(max(t.v3)) * sum0(count(t.v2)))) as $expr2] }
      └─StreamGlobalSimpleAgg { aggs: [min(min(t.v1)), max(max(t.v3)), sum0(count(t.v2)), count] }
        └─StreamExchange { dist: Single }
          └─StreamHashAgg { group_key: [$expr1], aggs: [min(t.v1), max(t.v3), count(t.v2), count] }
            └─StreamProject { exprs: [t.v1, t.v2, t.v3, t._row_id, Vnode(t._row_id) as $expr1] }
              └─StreamTableScan { table: t, columns: [t.v1, t.v2, t.v3, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: dup group key
  sql: |
    create table t(v1 int) with (appendonly = false);
    select v1 from t group by v1, v1;
  logical_plan: |
    LogicalProject { exprs: [t.v1] }
    └─LogicalAgg { group_key: [t.v1, t.v1], aggs: [] }
      └─LogicalProject { exprs: [t.v1] }
        └─LogicalScan { table: t, columns: [t.v1, t._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalProject { exprs: [t.v1] }
    └─LogicalProject { exprs: [t.v1, t.v1] }
      └─LogicalAgg { group_key: [t.v1], aggs: [] }
        └─LogicalScan { table: t, columns: [t.v1] }
  stream_plan: |
    StreamMaterialize { columns: [v1, t.v1(hidden)], pk_columns: [t.v1], pk_conflict: "no check" }
    └─StreamProject { exprs: [t.v1, t.v1] }
      └─StreamHashAgg { group_key: [t.v1], aggs: [count] }
        └─StreamExchange { dist: HashShard(t.v1) }
          └─StreamTableScan { table: t, columns: [t.v1, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: dup group key
  sql: |
    create table t(v1 int, v2 int, v3 int) with (appendonly = false);
    select v2, min(v1) as min_v1, v3, max(v1) as max_v1 from t group by v3, v2, v2;
  logical_plan: |
    LogicalProject { exprs: [t.v2, min(t.v1), t.v3, max(t.v1)] }
    └─LogicalAgg { group_key: [t.v3, t.v2, t.v2], aggs: [min(t.v1), max(t.v1)] }
      └─LogicalProject { exprs: [t.v3, t.v2, t.v1] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t.v3, t._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalProject { exprs: [t.v2, min(t.v1), t.v3, max(t.v1)] }
    └─LogicalProject { exprs: [t.v3, t.v2, t.v2, min(t.v1), max(t.v1)] }
      └─LogicalAgg { group_key: [t.v3, t.v2], aggs: [min(t.v1), max(t.v1)] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t.v3] }
  stream_plan: |
    StreamMaterialize { columns: [v2, min_v1, v3, max_v1, t.v2(hidden)], pk_columns: [v3, t.v2], pk_conflict: "no check" }
    └─StreamProject { exprs: [t.v2, min(t.v1), t.v3, max(t.v1), t.v2] }
      └─StreamHashAgg { group_key: [t.v3, t.v2], aggs: [min(t.v1), max(t.v1), count] }
        └─StreamExchange { dist: HashShard(t.v2, t.v3) }
          └─StreamTableScan { table: t, columns: [t.v1, t.v2, t.v3, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: order by agg input
  sql: |
    create table t(v1 int);
    select sum(v1 order by v1) as s1 from t;
  logical_plan: |
    LogicalProject { exprs: [sum(t.v1)] }
    └─LogicalAgg { aggs: [sum(t.v1)] }
      └─LogicalProject { exprs: [t.v1] }
        └─LogicalScan { table: t, columns: [t.v1, t._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalAgg { aggs: [sum(t.v1)] }
    └─LogicalScan { table: t, columns: [t.v1] }
  stream_plan: |
    StreamMaterialize { columns: [s1], pk_columns: [], pk_conflict: "no check" }
    └─StreamProject { exprs: [sum(sum(t.v1))] }
      └─StreamGlobalSimpleAgg { aggs: [sum(sum(t.v1)), count] }
        └─StreamExchange { dist: Single }
          └─StreamStatelessLocalSimpleAgg { aggs: [sum(t.v1)] }
            └─StreamTableScan { table: t, columns: [t.v1, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: order by other columns
  sql: |
    create table t(v1 int, v2 varchar);
    select sum(v1 order by v2) as s1 from t;
  logical_plan: |
    LogicalProject { exprs: [sum(t.v1)] }
    └─LogicalAgg { aggs: [sum(t.v1)] }
      └─LogicalProject { exprs: [t.v1] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalAgg { aggs: [sum(t.v1)] }
    └─LogicalScan { table: t, columns: [t.v1] }
  stream_plan: |
    StreamMaterialize { columns: [s1], pk_columns: [], pk_conflict: "no check" }
    └─StreamProject { exprs: [sum(sum(t.v1))] }
      └─StreamGlobalSimpleAgg { aggs: [sum(sum(t.v1)), count] }
        └─StreamExchange { dist: Single }
          └─StreamStatelessLocalSimpleAgg { aggs: [sum(t.v1)] }
            └─StreamTableScan { table: t, columns: [t.v1, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: order by ASC/DESC and default
  sql: |
    create table t(v1 int, v2 varchar, v3 int);
    select sum(v1 order by v1, v2 ASC, v3 DESC) as s1 from t;
  logical_plan: |
    LogicalProject { exprs: [sum(t.v1)] }
    └─LogicalAgg { aggs: [sum(t.v1)] }
      └─LogicalProject { exprs: [t.v1] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t.v3, t._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalAgg { aggs: [sum(t.v1)] }
    └─LogicalScan { table: t, columns: [t.v1] }
  stream_plan: |
    StreamMaterialize { columns: [s1], pk_columns: [], pk_conflict: "no check" }
    └─StreamProject { exprs: [sum(sum(t.v1))] }
      └─StreamGlobalSimpleAgg { aggs: [sum(sum(t.v1)), count] }
        └─StreamExchange { dist: Single }
          └─StreamStatelessLocalSimpleAgg { aggs: [sum(t.v1)] }
            └─StreamTableScan { table: t, columns: [t.v1, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: order by NULLS FIRST/LAST and default
  sql: |
    create table t(v1 int, v2 varchar, v3 int);
    select sum(v1 order by v1, v2 NULLS FIRST, v3 NULLS LAST) as s1 from t;
  logical_plan: |
    LogicalProject { exprs: [sum(t.v1)] }
    └─LogicalAgg { aggs: [sum(t.v1)] }
      └─LogicalProject { exprs: [t.v1] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t.v3, t._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalAgg { aggs: [sum(t.v1)] }
    └─LogicalScan { table: t, columns: [t.v1] }
  stream_plan: |
    StreamMaterialize { columns: [s1], pk_columns: [], pk_conflict: "no check" }
    └─StreamProject { exprs: [sum(sum(t.v1))] }
      └─StreamGlobalSimpleAgg { aggs: [sum(sum(t.v1)), count] }
        └─StreamExchange { dist: Single }
          └─StreamStatelessLocalSimpleAgg { aggs: [sum(t.v1)] }
            └─StreamTableScan { table: t, columns: [t.v1, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: order by complex expressions
  sql: |
    create table t(v1 int, v2 varchar, v3 int);
    select sum(v1 order by v1 + v3 ASC, length(v2) * v3 DESC NULLS FIRST) as s1 from t;
  logical_plan: |
    LogicalProject { exprs: [sum(t.v1)] }
    └─LogicalAgg { aggs: [sum(t.v1)] }
      └─LogicalProject { exprs: [t.v1] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t.v3, t._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalAgg { aggs: [sum(t.v1)] }
    └─LogicalScan { table: t, columns: [t.v1] }
  stream_plan: |
    StreamMaterialize { columns: [s1], pk_columns: [], pk_conflict: "no check" }
    └─StreamProject { exprs: [sum(sum(t.v1))] }
      └─StreamGlobalSimpleAgg { aggs: [sum(sum(t.v1)), count] }
        └─StreamExchange { dist: Single }
          └─StreamStatelessLocalSimpleAgg { aggs: [sum(t.v1)] }
            └─StreamTableScan { table: t, columns: [t.v1, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: filter clause
  sql: |
    create table t(v1 int);
    select sum(v1) FILTER (WHERE v1 > 0) AS sa from t;
  logical_plan: |
    LogicalProject { exprs: [sum(t.v1) filter((t.v1 > 0:Int32))] }
    └─LogicalAgg { aggs: [sum(t.v1) filter((t.v1 > 0:Int32))] }
      └─LogicalProject { exprs: [t.v1] }
        └─LogicalScan { table: t, columns: [t.v1, t._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalAgg { aggs: [sum(t.v1) filter((t.v1 > 0:Int32))] }
    └─LogicalScan { table: t, columns: [t.v1] }
  stream_plan: |
    StreamMaterialize { columns: [sa], pk_columns: [], pk_conflict: "no check" }
    └─StreamProject { exprs: [sum(sum(t.v1) filter((t.v1 > 0:Int32)))] }
      └─StreamGlobalSimpleAgg { aggs: [sum(sum(t.v1) filter((t.v1 > 0:Int32))), count] }
        └─StreamExchange { dist: Single }
          └─StreamStatelessLocalSimpleAgg { aggs: [sum(t.v1) filter((t.v1 > 0:Int32))] }
            └─StreamTableScan { table: t, columns: [t.v1, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: |
    filter clause
    extra calculation, should reuse result from project
  sql: |
    create table t(a int, b int);
    select sum(a * b) filter (where a * b > 0) as sab from t;
  logical_plan: |
    LogicalProject { exprs: [sum($expr1) filter(((t.a * t.b) > 0:Int32))] }
    └─LogicalAgg { aggs: [sum($expr1) filter(((t.a * t.b) > 0:Int32))] }
      └─LogicalProject { exprs: [t.a, t.b, (t.a * t.b) as $expr1] }
        └─LogicalScan { table: t, columns: [t.a, t.b, t._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalAgg { aggs: [sum($expr1) filter(((t.a * t.b) > 0:Int32))] }
    └─LogicalProject { exprs: [t.a, t.b, (t.a * t.b) as $expr1] }
      └─LogicalScan { table: t, columns: [t.a, t.b] }
- name: complex filter clause
  sql: |
    create table t(a int, b int);
    select max(a * b) FILTER (WHERE a < b AND a + b < 100 AND a * b != a + b - 1) AS sab from t;
  logical_plan: |
    LogicalProject { exprs: [max($expr1) filter((t.a < t.b) AND ((t.a + t.b) < 100:Int32) AND ((t.a * t.b) <> ((t.a + t.b) - 1:Int32)))] }
    └─LogicalAgg { aggs: [max($expr1) filter((t.a < t.b) AND ((t.a + t.b) < 100:Int32) AND ((t.a * t.b) <> ((t.a + t.b) - 1:Int32)))] }
      └─LogicalProject { exprs: [t.a, t.b, (t.a * t.b) as $expr1] }
        └─LogicalScan { table: t, columns: [t.a, t.b, t._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalAgg { aggs: [max($expr1) filter((t.a < t.b) AND ((t.a + t.b) < 100:Int32) AND ((t.a * t.b) <> ((t.a + t.b) - 1:Int32)))] }
    └─LogicalProject { exprs: [t.a, t.b, (t.a * t.b) as $expr1] }
      └─LogicalScan { table: t, columns: [t.a, t.b] }
  stream_plan: |
    StreamMaterialize { columns: [sab], pk_columns: [], pk_conflict: "no check" }
    └─StreamProject { exprs: [max(max($expr1) filter((t.a < t.b) AND ((t.a + t.b) < 100:Int32) AND ((t.a * t.b) <> ((t.a + t.b) - 1:Int32))))] }
      └─StreamGlobalSimpleAgg { aggs: [max(max($expr1) filter((t.a < t.b) AND ((t.a + t.b) < 100:Int32) AND ((t.a * t.b) <> ((t.a + t.b) - 1:Int32)))), count] }
        └─StreamExchange { dist: Single }
          └─StreamHashAgg { group_key: [$expr2], aggs: [max($expr1) filter((t.a < t.b) AND ((t.a + t.b) < 100:Int32) AND ((t.a * t.b) <> ((t.a + t.b) - 1:Int32))), count] }
            └─StreamProject { exprs: [t.a, t.b, $expr1, t._row_id, Vnode(t._row_id) as $expr2] }
              └─StreamProject { exprs: [t.a, t.b, (t.a * t.b) as $expr1, t._row_id] }
                └─StreamTableScan { table: t, columns: [t.a, t.b, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: avg filter clause + group by
  sql: |
    create table t(a int, b int);
    select avg(a) FILTER (WHERE a > b) AS avga from t group by b ;
  logical_plan: |
    LogicalProject { exprs: [(sum(t.a) filter((t.a > t.b))::Decimal / count(t.a) filter((t.a > t.b))) as $expr1] }
    └─LogicalAgg { group_key: [t.b], aggs: [sum(t.a) filter((t.a > t.b)), count(t.a) filter((t.a > t.b))] }
      └─LogicalProject { exprs: [t.b, t.a] }
        └─LogicalScan { table: t, columns: [t.a, t.b, t._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalProject { exprs: [(sum(t.a) filter((t.a > t.b))::Decimal / count(t.a) filter((t.a > t.b))) as $expr1] }
    └─LogicalAgg { group_key: [t.b], aggs: [sum(t.a) filter((t.a > t.b)), count(t.a) filter((t.a > t.b))] }
      └─LogicalScan { table: t, columns: [t.a, t.b] }
  stream_plan: |
    StreamMaterialize { columns: [avga, t.b(hidden)], pk_columns: [t.b], pk_conflict: "no check" }
    └─StreamProject { exprs: [(sum(t.a) filter((t.a > t.b))::Decimal / count(t.a) filter((t.a > t.b))) as $expr1, t.b] }
      └─StreamHashAgg { group_key: [t.b], aggs: [sum(t.a) filter((t.a > t.b)), count(t.a) filter((t.a > t.b)), count] }
        └─StreamExchange { dist: HashShard(t.b) }
          └─StreamTableScan { table: t, columns: [t.a, t.b, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: count filter clause
  sql: |
    create table t(a int, b int);
    select count(*) FILTER (WHERE a > b) AS cnt_agb from t;
  logical_plan: |
    LogicalProject { exprs: [count filter((t.a > t.b))] }
    └─LogicalAgg { aggs: [count filter((t.a > t.b))] }
      └─LogicalProject { exprs: [t.a, t.b] }
        └─LogicalScan { table: t, columns: [t.a, t.b, t._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalAgg { aggs: [count filter((t.a > t.b))] }
    └─LogicalScan { table: t, columns: [t.a, t.b] }
  stream_plan: |
    StreamMaterialize { columns: [cnt_agb], pk_columns: [], pk_conflict: "no check" }
    └─StreamProject { exprs: [sum0(count filter((t.a > t.b)))] }
      └─StreamGlobalSimpleAgg { aggs: [sum0(count filter((t.a > t.b))), count] }
        └─StreamExchange { dist: Single }
          └─StreamStatelessLocalSimpleAgg { aggs: [count filter((t.a > t.b))] }
            └─StreamTableScan { table: t, columns: [t.a, t.b, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: filter clause + non-boolean function
  sql: |
    create table t(a int, b int);
    select avg(a) FILTER (WHERE abs(a)) AS avga from t;
  binder_error: 'internal error: argument of FILTER must be boolean, not type Int32'
- name: filter clause + subquery
  sql: |
    create table t(a int, b int);
    select avg(a) FILTER (WHERE 0 < (select max(a) from t)) AS avga from t;
  binder_error: |-
    Feature is not yet implemented: subquery in filter clause
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- name: aggregation in filter clause
  sql: |
    create table t(a int, b int);
    select avg(a) FILTER (WHERE a < avg(b)) AS avga from t;
  binder_error: |-
    Feature is not yet implemented: aggregation function in filter clause
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- name: filter clause + non-boolean function
  sql: |
    create table t(a int, b int);
    select abs(a) FILTER (WHERE a > 0) AS avga from t;
  binder_error: 'Invalid input syntax: DISTINCT, ORDER BY or FILTER is only allowed in aggregation functions, but `abs` is not an aggregation function'
- name: prune column before filter
  sql: |
    create table t(v1 int, v2 int);
    with sub(a, b) as (select min(v1), sum(v2) filter (where v2 < 5) from t) select b from sub;
  batch_plan: |
    BatchSimpleAgg { aggs: [sum(sum(t.v2) filter((t.v2 < 5:Int32)))] }
    └─BatchExchange { order: [], dist: Single }
      └─BatchSimpleAgg { aggs: [sum(t.v2) filter((t.v2 < 5:Int32))] }
        └─BatchScan { table: t, columns: [t.v2], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [b], pk_columns: [], pk_conflict: "no check" }
    └─StreamProject { exprs: [sum(sum(t.v2) filter((t.v2 < 5:Int32)))] }
      └─StreamGlobalSimpleAgg { aggs: [sum(sum(t.v2) filter((t.v2 < 5:Int32))), count] }
        └─StreamExchange { dist: Single }
          └─StreamStatelessLocalSimpleAgg { aggs: [sum(t.v2) filter((t.v2 < 5:Int32))] }
            └─StreamTableScan { table: t, columns: [t.v2, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: only distinct agg
  sql: |
    create table t(a int, b int, c int);
    select a, count(distinct b) as distinct_b_num, sum(distinct c) filter(where c < 100) as distinct_c_sum from t group by a;
  optimized_logical_plan_for_batch: |
    LogicalAgg { group_key: [t.a], aggs: [count(t.b) filter((flag = 0:Int64)), sum(t.c) filter((count filter((t.c < 100:Int32)) > 0:Int64) AND (flag = 1:Int64))] }
    └─LogicalAgg { group_key: [t.a, t.b, t.c, flag], aggs: [count filter((t.c < 100:Int32))] }
      └─LogicalExpand { column_subsets: [[t.a, t.b], [t.a, t.c]] }
        └─LogicalScan { table: t, columns: [t.a, t.b, t.c] }
- name: single distinct agg and non-disintct agg
  sql: |
    create table t(a int, b int, c int);
    select a, count(distinct b) as distinct_b_num, sum(c) as sum_c from t group by a;
  optimized_logical_plan_for_batch: |
    LogicalAgg { group_key: [t.a], aggs: [count(t.b), sum(sum(t.c))] }
    └─LogicalAgg { group_key: [t.a, t.b], aggs: [sum(t.c)] }
      └─LogicalScan { table: t, columns: [t.a, t.b, t.c] }
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchHashAgg { group_key: [t.a], aggs: [count(t.b), sum(sum(t.c))] }
      └─BatchExchange { order: [], dist: HashShard(t.a) }
        └─BatchHashAgg { group_key: [t.a, t.b], aggs: [sum(t.c)] }
          └─BatchExchange { order: [], dist: HashShard(t.a, t.b) }
            └─BatchScan { table: t, columns: [t.a, t.b, t.c], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [a, distinct_b_num, sum_c], pk_columns: [a], pk_conflict: "no check" }
    └─StreamProject { exprs: [t.a, count(distinct t.b), sum(t.c)] }
      └─StreamHashAgg { group_key: [t.a], aggs: [count(distinct t.b), sum(t.c), count] }
        └─StreamExchange { dist: HashShard(t.a) }
          └─StreamTableScan { table: t, columns: [t.a, t.b, t.c, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: distinct agg and non-disintct agg with intersected argument
  sql: |
    create table t(a int, b int, c int);
    select a, count(distinct b) as distinct_b_num, count(distinct c) as distinct_c_sum, sum(c) as sum_c from t group by a;
  optimized_logical_plan_for_batch: |
    LogicalAgg { group_key: [t.a], aggs: [count(t.b) filter((flag = 1:Int64)), count(t.c) filter((flag = 0:Int64)), sum(sum(t.c)) filter((flag = 0:Int64))] }
    └─LogicalAgg { group_key: [t.a, t.b, t.c, flag], aggs: [sum(t.c)] }
      └─LogicalExpand { column_subsets: [[t.a, t.c], [t.a, t.b]] }
        └─LogicalScan { table: t, columns: [t.a, t.b, t.c] }
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchHashAgg { group_key: [t.a], aggs: [count(t.b) filter((flag = 1:Int64)), count(t.c) filter((flag = 0:Int64)), sum(sum(t.c)) filter((flag = 0:Int64))] }
      └─BatchExchange { order: [], dist: HashShard(t.a) }
        └─BatchHashAgg { group_key: [t.a, t.b, t.c, flag], aggs: [sum(t.c)] }
          └─BatchExchange { order: [], dist: HashShard(t.a, t.b, t.c, flag) }
            └─BatchExpand { column_subsets: [[t.a, t.c], [t.a, t.b]] }
              └─BatchScan { table: t, columns: [t.a, t.b, t.c], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [a, distinct_b_num, distinct_c_sum, sum_c], pk_columns: [a], pk_conflict: "no check" }
    └─StreamProject { exprs: [t.a, count(distinct t.b), count(distinct t.c), sum(t.c)] }
      └─StreamHashAgg { group_key: [t.a], aggs: [count(distinct t.b), count(distinct t.c), sum(t.c), count] }
        └─StreamExchange { dist: HashShard(t.a) }
          └─StreamTableScan { table: t, columns: [t.a, t.b, t.c, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: distinct agg with filter
  sql: |
    create table t(a int, b int, c int);
    select a, count(distinct b) filter(where b < 100), sum(c) from t group by a;
  optimized_logical_plan_for_batch: |
    LogicalAgg { group_key: [t.a], aggs: [count(t.b) filter((count filter((t.b < 100:Int32)) > 0:Int64)), sum(sum(t.c))] }
    └─LogicalAgg { group_key: [t.a, t.b], aggs: [count filter((t.b < 100:Int32)), sum(t.c)] }
      └─LogicalScan { table: t, columns: [t.a, t.b, t.c] }
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchHashAgg { group_key: [t.a], aggs: [count(t.b) filter((count filter((t.b < 100:Int32)) > 0:Int64)), sum(sum(t.c))] }
      └─BatchExchange { order: [], dist: HashShard(t.a) }
        └─BatchHashAgg { group_key: [t.a, t.b], aggs: [count filter((t.b < 100:Int32)), sum(t.c)] }
          └─BatchExchange { order: [], dist: HashShard(t.a, t.b) }
            └─BatchScan { table: t, columns: [t.a, t.b, t.c], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [a, count, sum], pk_columns: [a], pk_conflict: "no check" }
    └─StreamProject { exprs: [t.a, count(distinct t.b) filter((t.b < 100:Int32)), sum(t.c)] }
      └─StreamHashAgg { group_key: [t.a], aggs: [count(distinct t.b) filter((t.b < 100:Int32)), sum(t.c), count] }
        └─StreamExchange { dist: HashShard(t.a) }
          └─StreamTableScan { table: t, columns: [t.a, t.b, t.c, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: non-distinct agg with filter
  sql: |
    create table t(a int, b int, c int);
    select a, count(distinct b), sum(c) filter(where b < 100) from t group by a;
  optimized_logical_plan_for_batch: |
    LogicalAgg { group_key: [t.a], aggs: [count(t.b), sum(sum(t.c) filter((t.b < 100:Int32)))] }
    └─LogicalAgg { group_key: [t.a, t.b], aggs: [sum(t.c) filter((t.b < 100:Int32))] }
      └─LogicalScan { table: t, columns: [t.a, t.b, t.c] }
- name: combined order by & filter clauses
  sql: |
    create table t(a varchar, b int);
    select sum(length(a) * b order by length(a) + b) filter (where b < 100 AND b * 2 > 10) as s1 from t;
  logical_plan: |
    LogicalProject { exprs: [sum($expr1) filter((t.b < 100:Int32) AND ((t.b * 2:Int32) > 10:Int32))] }
    └─LogicalAgg { aggs: [sum($expr1) filter((t.b < 100:Int32) AND ((t.b * 2:Int32) > 10:Int32))] }
      └─LogicalProject { exprs: [t.b, (Length(t.a) * t.b) as $expr1] }
        └─LogicalScan { table: t, columns: [t.a, t.b, t._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalAgg { aggs: [sum($expr1) filter((t.b < 100:Int32) AND ((t.b * 2:Int32) > 10:Int32))] }
    └─LogicalProject { exprs: [t.b, (Length(t.a) * t.b) as $expr1] }
      └─LogicalScan { table: t, columns: [t.a, t.b] }
  stream_plan: |
    StreamMaterialize { columns: [s1], pk_columns: [], pk_conflict: "no check" }
    └─StreamProject { exprs: [sum(sum($expr1) filter((t.b < 100:Int32) AND ((t.b * 2:Int32) > 10:Int32)))] }
      └─StreamGlobalSimpleAgg { aggs: [sum(sum($expr1) filter((t.b < 100:Int32) AND ((t.b * 2:Int32) > 10:Int32))), count] }
        └─StreamExchange { dist: Single }
          └─StreamStatelessLocalSimpleAgg { aggs: [sum($expr1) filter((t.b < 100:Int32) AND ((t.b * 2:Int32) > 10:Int32))] }
            └─StreamProject { exprs: [t.b, (Length(t.a) * t.b) as $expr1, t._row_id] }
              └─StreamTableScan { table: t, columns: [t.a, t.b, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    create table t(x int, y varchar);
    select string_agg(y, ',' order by y), count(distinct x) from t;
  planner_error: 'Invalid input syntax: Order by aggregates are disallowed to occur with distinct aggregates'
- sql: |
    create table t(v1 int, v2 int);
    with z(a, b) as (select count(distinct v1), count(v2) from t) select a from z;
  optimized_logical_plan_for_batch: |
    LogicalAgg { aggs: [count(t.v1)] }
    └─LogicalAgg { group_key: [t.v1], aggs: [] }
      └─LogicalScan { table: t, columns: [t.v1] }
- name: input is sharded by group key
  sql: |
    create table t(x int);
    create index i on t(x);
    select count(*) as cnt from i group by x;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [count] }
      └─BatchSortAgg { group_key: [i.x], aggs: [count] }
        └─BatchScan { table: i, columns: [i.x], distribution: UpstreamHashShard(i.x) }
  stream_plan: |
    StreamMaterialize { columns: [cnt, i.x(hidden)], pk_columns: [i.x], pk_conflict: "no check" }
    └─StreamProject { exprs: [count, i.x] }
      └─StreamHashAgg { group_key: [i.x], aggs: [count] }
        └─StreamTableScan { table: i, columns: [i.x, i.t._row_id], pk: [i.t._row_id], dist: UpstreamHashShard(i.x) }
- name: distinct aggregates only have one distinct argument doesn't need expand
  sql: |
    create table t(x int, y int);
    select count(x), sum(distinct y), sum(distinct y) from t;
  optimized_logical_plan_for_batch: |
    LogicalProject { exprs: [sum0(count(t.x)), sum(t.y), sum(t.y)] }
    └─LogicalAgg { aggs: [sum0(count(t.x)), sum(t.y)] }
      └─LogicalAgg { group_key: [t.y], aggs: [count(t.x)] }
        └─LogicalScan { table: t, columns: [t.x, t.y] }
- sql: |
    create table t(x int, y int);
    select count(y), sum(distinct y) from t;
  optimized_logical_plan_for_batch: |
    LogicalAgg { aggs: [sum0(count(t.y)), sum(t.y)] }
    └─LogicalAgg { group_key: [t.y], aggs: [count(t.y)] }
      └─LogicalScan { table: t, columns: [t.y] }
- sql: |
    create table t(x int, y int);
    select count(distinct x), sum(distinct y) from t;
  optimized_logical_plan_for_batch: |
    LogicalAgg { aggs: [count(t.x) filter((flag = 0:Int64)), sum(t.y) filter((flag = 1:Int64))] }
    └─LogicalAgg { group_key: [t.x, t.y, flag], aggs: [] }
      └─LogicalExpand { column_subsets: [[t.x], [t.y]] }
        └─LogicalScan { table: t, columns: [t.x, t.y] }
- sql: |
    create table t(x varchar, y int);
    select string_agg(x, ','), count(distinct y) from t;
  planner_error: |-
    Feature is not yet implemented: Non-distinct string_agg can't appear with distinct aggregates
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- name: remove unnecessary distinct for max and min
  sql: |
    create table t(x int, y int);
    select max(distinct x), min(distinct y) from t;
  optimized_logical_plan_for_batch: |
    LogicalAgg { aggs: [max(t.x), min(t.y)] }
    └─LogicalScan { table: t, columns: [t.x, t.y] }
- name: agg filter - subquery
  sql: |
    /* This case is valid in PostgreSQL */
    create table a (a1 int, a2 int);
    select count(a1) filter (where (select true)) from a;
  binder_error: |-
    Feature is not yet implemented: subquery in filter clause
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- name: agg filter - agg
  sql: |
    /* This case is valid in PostgreSQL */
    create table a (a1 int, a2 int);
    create table b (b1 int, b2 int);
    select 1 from a having exists(
      select count(b1) filter (where min(a1) < 3) from b
    );
  binder_error: |-
    Feature is not yet implemented: aggregation function in filter clause
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- name: agg filter - table function
  sql: |
    /* This case is NOT valid in PostgreSQL */
    create table a (a1 int, a2 int);
    select count(a1) filter (where unnest(array[1]) < 1) from a;
  binder_error: |-
    Feature is not yet implemented: table function in filter clause
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- name: agg order by - subquery
  sql: |
    /* This case is valid in PostgreSQL */
    create table a (a1 int, a2 int);
    select string_agg('', '' order by (select true)) from a;
  planner_error: |-
    Feature is not yet implemented: subquery inside aggregation calls order by
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- name: agg order by - agg (correlated in having)
  sql: |
    create table a (a1 int, a2 int);
    create table sb (b1 varchar, b2 varchar);
    select 1 from a having exists(
      select string_agg(b1, '' order by min(a1)) from sb -- valid in PostgreSQL
      -- select string_agg('', '' order by min(a1)) from sb -- NOT valid in PostgreSQL
    );
  planner_error: |-
    Feature is not yet implemented: correlated subquery in HAVING or SELECT with agg
    Tracking issue: https://github.com/risingwavelabs/risingwave/issues/2275
- name: agg order by - agg (correlated in where)
  sql: |
    /* This case is NOT valid in PostgreSQL */
    create table a (a1 int, a2 int);
    create table sb (b1 varchar, b2 varchar);
    select 1 from a where exists(
      select string_agg(b1, '' order by min(a1)) from sb
    );
  planner_error: |-
    Feature is not yet implemented: aggregate function inside aggregation calls order by
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- name: agg order by - table function
  sql: |
    /* This case is NOT valid in PostgreSQL */
    create table a (a1 int, a2 int);
    select string_agg('', '' order by unnest(array[1])) from a;
  planner_error: |-
    Feature is not yet implemented: table function inside aggregation calls order by
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- name: agg input - subquery
  sql: |
    /* This case is valid in PostgreSQL */
    create table a (a1 int, a2 int);
    select count(a1 + (select 1)) from a;
  planner_error: |-
    Feature is not yet implemented: subquery inside aggregation calls
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- name: agg input - agg
  sql: |
    /* This case is valid in PostgreSQL */
    create table a (a1 int, a2 int);
    create table b (b1 int, b2 int);
    select 1 from a having exists(
      select count(b1 + min(a1)) from b
    );
  planner_error: |-
    Feature is not yet implemented: correlated subquery in HAVING or SELECT with agg
    Tracking issue: https://github.com/risingwavelabs/risingwave/issues/2275
- name: agg input - table function
  sql: |
    /* This case is NOT valid in PostgreSQL */
    create table a (a1 int, a2 int);
    select count(a1 + unnest(array[1])) from a;
  planner_error: |-
    Feature is not yet implemented: table function inside aggregation calls
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- name: group by - subquery
  sql: |
    /* This case is valid in PostgreSQL */
    create table a (a1 int, a2 int);
    select count(a1) from a group by (select true);
  planner_error: |-
    Feature is not yet implemented: subquery inside GROUP BY
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- name: group by - agg
  sql: |
    /* This case is valid in PostgreSQL */
    create table a (a1 int, a2 int);
    create table b (b1 int, b2 int);
    select 1 from a having exists(
      select count(b1) from b group by min(a1)
    );
  planner_error: |-
    Feature is not yet implemented: correlated subquery in HAVING or SELECT with agg
    Tracking issue: https://github.com/risingwavelabs/risingwave/issues/2275
- name: group by - table function
  sql: |
    /* This case is valid in PostgreSQL */
    create table a (a1 int, a2 int);
    select count(a1) from a group by unnest(array[1]);
  planner_error: |-
    Feature is not yet implemented: table function inside GROUP BY
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- name: post-agg project set - ok
  sql: |
    create table t (v1 int, v2 int);
    select min(v1), unnest(array[2, max(v2)]) from t;
  logical_plan: |
    LogicalProject { exprs: [min(t.v1), Unnest(Array(2:Int32, $1))] }
    └─LogicalProjectSet { select_list: [$0, Unnest(Array(2:Int32, $1))] }
      └─LogicalAgg { aggs: [min(t.v1), max(t.v2)] }
        └─LogicalProject { exprs: [t.v1, t.v2] }
          └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id] }
- name: post-agg project set - error
  sql: |
    create table t (v1 int, v2 int);
    select min(v1), unnest(array[2, v2]) from t;
  planner_error: 'Invalid input syntax: column must appear in the GROUP BY clause or be used in an aggregate function'
- name: post-agg project set - grouped
  sql: |
    create table t (v1 int, v2 int);
    select min(v1), unnest(array[2, v2]) from t group by v2;
  logical_plan: |
    LogicalProject { exprs: [min(t.v1), Unnest(Array(2:Int32, $0))] }
    └─LogicalProjectSet { select_list: [$1, Unnest(Array(2:Int32, $0))] }
      └─LogicalAgg { group_key: [t.v2], aggs: [min(t.v1)] }
        └─LogicalProject { exprs: [t.v2, t.v1] }
          └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id] }
- name: min/max on index
  sql: |
    create table t (v1 varchar, v2 int);
    create index idx on t(v2 desc);
    select max(v2) from t;
  logical_plan: |
    LogicalProject { exprs: [max(t.v2)] }
    └─LogicalAgg { aggs: [max(t.v2)] }
      └─LogicalProject { exprs: [t.v2] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalAgg { aggs: [max(idx.v2)] }
    └─LogicalLimit { limit: 1, offset: 0 }
      └─LogicalFilter { predicate: IsNotNull(idx.v2) }
        └─LogicalScan { table: idx, columns: [idx.v2] }
- name: min/max on index with group by, shall NOT optimize
  sql: |
    create table t (v1 int, v2 int);
    create index idx on t(v2 desc);
    select max(v2) from t group by v1;
  logical_plan: |
    LogicalProject { exprs: [max(t.v2)] }
    └─LogicalAgg { group_key: [t.v1], aggs: [max(t.v2)] }
      └─LogicalProject { exprs: [t.v1, t.v2] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalProject { exprs: [max(t.v2)] }
    └─LogicalAgg { group_key: [t.v1], aggs: [max(t.v2)] }
      └─LogicalScan { table: t, columns: [t.v1, t.v2] }
- name: min/max on primary key
  sql: |
    create table t (v1 int primary key);
    select min(v1) from t;
  logical_plan: |
    LogicalProject { exprs: [min(t.v1)] }
    └─LogicalAgg { aggs: [min(t.v1)] }
      └─LogicalProject { exprs: [t.v1] }
        └─LogicalScan { table: t, columns: [t.v1] }
  optimized_logical_plan_for_batch: |
    LogicalAgg { aggs: [min(t.v1)] }
    └─LogicalLimit { limit: 1, offset: 0 }
      └─LogicalFilter { predicate: IsNotNull(t.v1) }
        └─LogicalScan { table: t, columns: [t.v1] }
- name: stddev_samp
  sql: |
    create table t (v1 int);
    select stddev_samp(v1), stddev_pop(v1) from t;
  logical_plan: |
    LogicalProject { exprs: [Case((count(t.v1) <= 1:Int64), null:Decimal::Float64, Pow(((sum($expr1)::Decimal - ((sum(t.v1)::Decimal * sum(t.v1)::Decimal) / count(t.v1))) / (count(t.v1) - 1:Int64))::Float64, 0.5:Float64)) as $expr2, Pow(((sum($expr1)::Decimal - ((sum(t.v1)::Decimal * sum(t.v1)::Decimal) / count(t.v1))) / count(t.v1))::Float64, 0.5:Float64) as $expr3] }
    └─LogicalAgg { aggs: [sum($expr1), sum(t.v1), count(t.v1)] }
      └─LogicalProject { exprs: [t.v1, (t.v1 * t.v1) as $expr1] }
        └─LogicalScan { table: t, columns: [t.v1, t._row_id] }
  batch_plan: |
    BatchProject { exprs: [Case((sum0(count(t.v1)) <= 1:Int64), null:Float64, Pow(((sum(sum($expr1))::Decimal - ((sum(sum(t.v1))::Decimal * sum(sum(t.v1))::Decimal) / sum0(count(t.v1)))) / (sum0(count(t.v1)) - 1:Int64))::Float64, 0.5:Float64)) as $expr2, Pow(((sum(sum($expr1))::Decimal - ((sum(sum(t.v1))::Decimal * sum(sum(t.v1))::Decimal) / sum0(count(t.v1)))) / sum0(count(t.v1)))::Float64, 0.5:Float64) as $expr3] }
    └─BatchSimpleAgg { aggs: [sum(sum($expr1)), sum(sum(t.v1)), sum0(count(t.v1))] }
      └─BatchExchange { order: [], dist: Single }
        └─BatchSimpleAgg { aggs: [sum($expr1), sum(t.v1), count(t.v1)] }
          └─BatchProject { exprs: [t.v1, (t.v1 * t.v1) as $expr1] }
            └─BatchScan { table: t, columns: [t.v1], distribution: SomeShard }
  batch_local_plan: |
    BatchProject { exprs: [Case((count(t.v1) <= 1:Int64), null:Float64, Pow(((sum($expr1)::Decimal - ((sum(t.v1)::Decimal * sum(t.v1)::Decimal) / count(t.v1))) / (count(t.v1) - 1:Int64))::Float64, 0.5:Float64)) as $expr2, Pow(((sum($expr1)::Decimal - ((sum(t.v1)::Decimal * sum(t.v1)::Decimal) / count(t.v1))) / count(t.v1))::Float64, 0.5:Float64) as $expr3] }
    └─BatchSimpleAgg { aggs: [sum($expr1), sum(t.v1), count(t.v1)] }
      └─BatchExchange { order: [], dist: Single }
        └─BatchProject { exprs: [t.v1, (t.v1 * t.v1) as $expr1] }
          └─BatchScan { table: t, columns: [t.v1], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [stddev_samp, stddev_pop], pk_columns: [], pk_conflict: "no check" }
    └─StreamProject { exprs: [Case((sum0(count(t.v1)) <= 1:Int64), null:Float64, Pow(((sum(sum($expr1))::Decimal - ((sum(sum(t.v1))::Decimal * sum(sum(t.v1))::Decimal) / sum0(count(t.v1)))) / (sum0(count(t.v1)) - 1:Int64))::Float64, 0.5:Float64)) as $expr2, Pow(((sum(sum($expr1))::Decimal - ((sum(sum(t.v1))::Decimal * sum(sum(t.v1))::Decimal) / sum0(count(t.v1)))) / sum0(count(t.v1)))::Float64, 0.5:Float64) as $expr3] }
      └─StreamGlobalSimpleAgg { aggs: [sum(sum($expr1)), sum(sum(t.v1)), sum0(count(t.v1)), count] }
        └─StreamExchange { dist: Single }
          └─StreamStatelessLocalSimpleAgg { aggs: [sum($expr1), sum(t.v1), count(t.v1)] }
            └─StreamProject { exprs: [t.v1, (t.v1 * t.v1) as $expr1, t._row_id] }
              └─StreamTableScan { table: t, columns: [t.v1, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: force two phase aggregation should succeed with UpstreamHashShard and SomeShard (batch only).
  sql: |
    SET QUERY_MODE TO DISTRIBUTED;
    SET RW_FORCE_TWO_PHASE_AGG=true;
    create table t(v1 int, v2 smallint, v3 varchar);
    select min(v3), sum(v1) from t group by v1, v3, v2;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [min(min(t.v3)), sum(sum(t.v1))] }
      └─BatchHashAgg { group_key: [t.v1, t.v3, t.v2], aggs: [min(min(t.v3)), sum(sum(t.v1))] }
        └─BatchExchange { order: [], dist: HashShard(t.v1, t.v3, t.v2) }
          └─BatchHashAgg { group_key: [t.v1, t.v3, t.v2], aggs: [min(t.v3), sum(t.v1)] }
            └─BatchScan { table: t, columns: [t.v1, t.v2, t.v3], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [min, sum, t.v1(hidden), t.v3(hidden), t.v2(hidden)], pk_columns: [t.v1, t.v3, t.v2], pk_conflict: "no check" }
    └─StreamProject { exprs: [min(min(t.v3)), sum(sum(t.v1)), t.v1, t.v3, t.v2] }
      └─StreamHashAgg { group_key: [t.v1, t.v3, t.v2], aggs: [min(min(t.v3)), sum(sum(t.v1)), count] }
        └─StreamExchange { dist: HashShard(t.v1, t.v3, t.v2) }
          └─StreamHashAgg { group_key: [t.v1, t.v3, t.v2, $expr1], aggs: [min(t.v3), sum(t.v1), count] }
            └─StreamProject { exprs: [t.v1, t.v2, t.v3, t._row_id, Vnode(t._row_id) as $expr1] }
              └─StreamTableScan { table: t, columns: [t.v1, t.v2, t.v3, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: enable two phase aggregation with simple agg should have two phase agg
  sql: |
    SET QUERY_MODE TO DISTRIBUTED;
    SET RW_ENABLE_TWO_PHASE_AGG=true;
    create table t(v1 int, v2 int);
    select min(v1), sum(v2) from t;
  batch_plan: |
    BatchSimpleAgg { aggs: [min(min(t.v1)), sum(sum(t.v2))] }
    └─BatchExchange { order: [], dist: Single }
      └─BatchSimpleAgg { aggs: [min(t.v1), sum(t.v2)] }
        └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [min, sum], pk_columns: [], pk_conflict: "no check" }
    └─StreamProject { exprs: [min(min(t.v1)), sum(sum(t.v2))] }
      └─StreamGlobalSimpleAgg { aggs: [min(min(t.v1)), sum(sum(t.v2)), count] }
        └─StreamExchange { dist: Single }
          └─StreamHashAgg { group_key: [$expr1], aggs: [min(t.v1), sum(t.v2), count] }
            └─StreamProject { exprs: [t.v1, t.v2, t._row_id, Vnode(t._row_id) as $expr1] }
              └─StreamTableScan { table: t, columns: [t.v1, t.v2, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: disable two phase aggregation with simple agg
  sql: |
    SET QUERY_MODE TO DISTRIBUTED;
    SET RW_ENABLE_TWO_PHASE_AGG=false;
    create table t(v1 int, v2 int);
    select min(v1), sum(v2) from t;
  batch_plan: |
    BatchSimpleAgg { aggs: [min(t.v1), sum(t.v2)] }
    └─BatchExchange { order: [], dist: Single }
      └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [min, sum], pk_columns: [], pk_conflict: "no check" }
    └─StreamProject { exprs: [min(t.v1), sum(t.v2)] }
      └─StreamGlobalSimpleAgg { aggs: [min(t.v1), sum(t.v2), count] }
        └─StreamExchange { dist: Single }
          └─StreamTableScan { table: t, columns: [t.v1, t.v2, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: force two phase agg with different distributions on inner and outer agg should have exchange
  sql: |
    set QUERY_MODE to DISTRIBUTED;
    set RW_FORCE_TWO_PHASE_AGG to TRUE;
    CREATE TABLE lineitem (
        l_orderkey BIGINT,
        l_tax NUMERIC,
        l_commitdate DATE,
        l_shipinstruct VARCHAR,
        PRIMARY KEY (l_orderkey)
    );
    SELECT
        max(sq_1.col_2) as col_0
    FROM
        (
            SELECT
                t_0.l_commitdate AS col_2
            FROM
                lineitem AS t_0
            GROUP BY
                t_0.l_tax,
                t_0.l_shipinstruct,
                t_0.l_orderkey,
                t_0.l_commitdate
        ) AS sq_1
    GROUP BY
        sq_1.col_2;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [max(max(lineitem.l_commitdate))] }
      └─BatchHashAgg { group_key: [lineitem.l_commitdate], aggs: [max(max(lineitem.l_commitdate))] }
        └─BatchExchange { order: [], dist: HashShard(lineitem.l_commitdate) }
          └─BatchHashAgg { group_key: [lineitem.l_commitdate], aggs: [max(lineitem.l_commitdate)] }
            └─BatchHashAgg { group_key: [lineitem.l_tax, lineitem.l_shipinstruct, lineitem.l_orderkey, lineitem.l_commitdate], aggs: [] }
              └─BatchScan { table: lineitem, columns: [lineitem.l_orderkey, lineitem.l_tax, lineitem.l_commitdate, lineitem.l_shipinstruct], distribution: UpstreamHashShard(lineitem.l_orderkey) }
  stream_plan: |
    StreamMaterialize { columns: [col_0, lineitem.l_commitdate(hidden)], pk_columns: [lineitem.l_commitdate], pk_conflict: "no check" }
    └─StreamProject { exprs: [max(max(lineitem.l_commitdate)), lineitem.l_commitdate] }
      └─StreamHashAgg { group_key: [lineitem.l_commitdate], aggs: [max(max(lineitem.l_commitdate)), count] }
        └─StreamExchange { dist: HashShard(lineitem.l_commitdate) }
          └─StreamHashAgg { group_key: [lineitem.l_commitdate, $expr1], aggs: [max(lineitem.l_commitdate), count] }
            └─StreamProject { exprs: [lineitem.l_tax, lineitem.l_shipinstruct, lineitem.l_orderkey, lineitem.l_commitdate, Vnode(lineitem.l_orderkey) as $expr1] }
              └─StreamProject { exprs: [lineitem.l_tax, lineitem.l_shipinstruct, lineitem.l_orderkey, lineitem.l_commitdate] }
                └─StreamHashAgg { group_key: [lineitem.l_tax, lineitem.l_shipinstruct, lineitem.l_orderkey, lineitem.l_commitdate], aggs: [count] }
                  └─StreamTableScan { table: lineitem, columns: [lineitem.l_orderkey, lineitem.l_tax, lineitem.l_commitdate, lineitem.l_shipinstruct], pk: [lineitem.l_orderkey], dist: UpstreamHashShard(lineitem.l_orderkey) }
- name: two phase agg on hop window input should use two phase agg
  sql: |
    SET QUERY_MODE TO DISTRIBUTED;
    SET RW_FORCE_TWO_PHASE_AGG=true;
    create table bid(date_time TIMESTAMP, auction int);
    SELECT
      max(CountBids.num) AS maxn,
      CountBids.starttime_c
    FROM (
      SELECT
        count(*) AS num,
        window_start AS starttime_c
      FROM HOP(bid, date_time, INTERVAL '2' SECOND, INTERVAL '10' SECOND)
      GROUP BY
        bid.auction,
        window_start
    ) as CountBids
    GROUP BY
    CountBids.starttime_c;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [max(max(sum0(count))), window_start] }
      └─BatchHashAgg { group_key: [window_start], aggs: [max(max(sum0(count)))] }
        └─BatchExchange { order: [], dist: HashShard(window_start) }
          └─BatchHashAgg { group_key: [window_start], aggs: [max(sum0(count))] }
            └─BatchHashAgg { group_key: [bid.auction, window_start], aggs: [sum0(count)] }
              └─BatchExchange { order: [], dist: HashShard(bid.auction, window_start) }
                └─BatchHashAgg { group_key: [bid.auction, window_start], aggs: [count] }
                  └─BatchHopWindow { time_col: bid.date_time, slide: 00:00:02, size: 00:00:10, output: [bid.auction, window_start] }
                    └─BatchFilter { predicate: IsNotNull(bid.date_time) }
                      └─BatchScan { table: bid, columns: [bid.date_time, bid.auction], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [maxn, starttime_c], pk_columns: [starttime_c], pk_conflict: "no check" }
    └─StreamProject { exprs: [max(max(sum0(count))), window_start] }
      └─StreamHashAgg { group_key: [window_start], aggs: [max(max(sum0(count))), count] }
        └─StreamExchange { dist: HashShard(window_start) }
          └─StreamHashAgg { group_key: [window_start, $expr2], aggs: [max(sum0(count)), count] }
            └─StreamProject { exprs: [bid.auction, window_start, sum0(count), Vnode(bid.auction, window_start) as $expr2] }
              └─StreamProject { exprs: [bid.auction, window_start, sum0(count)] }
                └─StreamHashAgg { group_key: [bid.auction, window_start], aggs: [sum0(count), count] }
                  └─StreamExchange { dist: HashShard(bid.auction, window_start) }
                    └─StreamHashAgg { group_key: [bid.auction, window_start, $expr1], aggs: [count] }
                      └─StreamProject { exprs: [bid.auction, window_start, bid._row_id, Vnode(bid._row_id) as $expr1] }
                        └─StreamHopWindow { time_col: bid.date_time, slide: 00:00:02, size: 00:00:10, output: [bid.auction, window_start, bid._row_id] }
                          └─StreamFilter { predicate: IsNotNull(bid.date_time) }
                            └─StreamTableScan { table: bid, columns: [bid.date_time, bid.auction, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
- name: two phase agg with stream SomeShard (via index) but pk satisfies output dist should use shuffle agg
  sql: |
    SET QUERY_MODE TO DISTRIBUTED;
    SET RW_FORCE_TWO_PHASE_AGG=true;
    create table t (id int primary key, col int);
    create index idx on t(col);
    with sq as (select id from idx) select count(*) from sq group by sq.id;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [sum0(count)] }
      └─BatchHashAgg { group_key: [idx.id], aggs: [sum0(count)] }
        └─BatchExchange { order: [], dist: HashShard(idx.id) }
          └─BatchHashAgg { group_key: [idx.id], aggs: [count] }
            └─BatchScan { table: idx, columns: [idx.id], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [count, idx.id(hidden)], pk_columns: [idx.id], pk_conflict: "no check" }
    └─StreamProject { exprs: [count, idx.id] }
      └─StreamHashAgg { group_key: [idx.id], aggs: [count] }
        └─StreamExchange { dist: HashShard(idx.id) }
          └─StreamTableScan { table: idx, columns: [idx.id], pk: [idx.id], dist: SomeShard }
- name: two phase agg with stream SomeShard (via index) but pk does not satisfy output dist should use two phase agg
  sql: |
    SET QUERY_MODE TO DISTRIBUTED;
    SET RW_FORCE_TWO_PHASE_AGG=true;
    create table t (id int primary key, col1 int, col2 int);
    create index idx on t(id);
    with sq as (select col1, col2 from idx) select count(*) from sq group by sq.col1;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [sum0(count)] }
      └─BatchHashAgg { group_key: [idx.col1], aggs: [sum0(count)] }
        └─BatchExchange { order: [], dist: HashShard(idx.col1) }
          └─BatchHashAgg { group_key: [idx.col1], aggs: [count] }
            └─BatchScan { table: idx, columns: [idx.col1], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [count, idx.col1(hidden)], pk_columns: [idx.col1], pk_conflict: "no check" }
    └─StreamProject { exprs: [sum0(count), idx.col1] }
      └─StreamHashAgg { group_key: [idx.col1], aggs: [sum0(count), count] }
        └─StreamExchange { dist: HashShard(idx.col1) }
          └─StreamHashAgg { group_key: [idx.col1, $expr1], aggs: [count] }
            └─StreamProject { exprs: [idx.col1, idx.id, Vnode(idx.id) as $expr1] }
              └─StreamTableScan { table: idx, columns: [idx.col1, idx.id], pk: [idx.id], dist: UpstreamHashShard(idx.id) }
